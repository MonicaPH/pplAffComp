{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Hyperbole using RSA\n",
    "(This tutorial written by Noah Goodman and Eli Bingham, following Kao, Wu, Bergen, and Goodman (2014).)\n",
    "\n",
    "    \"My new kettle cost a million dollars.\"\n",
    "\n",
    "Hyperbole -- using an exagerated utterance to convey strong opinions -- is a common non-literal use of language. Yet non-literal uses of langauge are impossible under the simplest RSA model. Kao, et al, suggested that two ingredients could be added to ennable RSA to capture hyperbole. First, the state conveyed by the speaker and reasoned about by the listener should include affective dimensions. Second, the speaker only intends to convey information relevant to a particular topic, such as \"how expensive was it?\" or \"how am I feeling about the price?\"; pragmatic listeners hence jointly reason about this topic and the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first some imports\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)  # double precision for numerical stability\n",
    "\n",
    "import collections\n",
    "import argparse\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ngoodman/pplAffComp/code/utils\n"
     ]
    }
   ],
   "source": [
    "cd \"utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_inference import factor, HashingMarginal, memoize, Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the simple RSA example, the inferece helper `Marginal` takes an un-normalized stochastic function, constructs the distribution over execution traces by using `Search`, and constructs the marginal distribution on return values (via `HashingMarginal`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Marginal(fn):\n",
    "    return memoize(lambda *args: HashingMarginal(Search(fn).run(*args)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain for this example will be states consisting of price (e.g. of a tea kettle) and the speaker's emotional arousal (whether the speaker thinks this price is irritatingly expensive). Priors here are adapted from experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = collections.namedtuple(\"State\", [\"price\", \"arousal\"])\n",
    "\n",
    "def price_prior():\n",
    "    values = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
    "    probs = torch.tensor([0.4205, 0.3865, 0.0533, 0.0538, 0.0223, 0.0211, 0.0112, 0.0111, 0.0083, 0.0120])\n",
    "    ix = pyro.sample(\"price\", dist.Categorical(probs=probs))\n",
    "    return values[ix]\n",
    "\n",
    "def arousal_prior(price):\n",
    "    probs = {\n",
    "        50: 0.3173,\n",
    "        51: 0.3173,\n",
    "        500: 0.7920,\n",
    "        501: 0.7920,\n",
    "        1000: 0.8933,\n",
    "        1001: 0.8933,\n",
    "        5000: 0.9524,\n",
    "        5001: 0.9524,\n",
    "        10000: 0.9864,\n",
    "        10001: 0.9864\n",
    "    }\n",
    "    return pyro.sample(\"arousal\", dist.Bernoulli(probs=probs[price])).item() == 1\n",
    "\n",
    "def state_prior():\n",
    "    price = price_prior()\n",
    "    state = State(price=price, arousal=arousal_prior(price))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a version of the RSA speaker that only produces *relevant* information for the literal listener. We define relevance with respect to a Question Under Discussion (QUD) -- this can be thought of as defining the speaker's current attention or topic.\n",
    "\n",
    "The speaker is defined mathematically by:\n",
    "\n",
    "$$P_S(u|s,q) \\propto \\left[ \\sum_{w'} \\delta_{q(w')=q(w)} P_\\text{Lit}(w'|u) p(u) \\right]^\\alpha $$\n",
    "\n",
    "To implement this as a probabilistic program, we start with a helper function `project`, which takes a distribution over some (discrete) domain and a function `qud` on this domain. It creates the push-forward distribution, using `Marginal` (as a Python decorator). The speaker's relevant information is then simply information about the state in this projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def project(dist,qud):\n",
    "    v = pyro.sample(\"proj\",dist)\n",
    "    return qud_fns[qud](v)\n",
    "\n",
    "@Marginal\n",
    "def literal_listener(utterance):\n",
    "    state=state_prior()\n",
    "    factor(\"literal_meaning\", 0. if meaning(utterance, state.price) else -999999.)\n",
    "    return state\n",
    "\n",
    "@Marginal\n",
    "def speaker(state, qud):\n",
    "    alpha = 1.\n",
    "    qudValue = qud_fns[qud](state)\n",
    "    with poutine.scale(scale=torch.tensor(alpha)):\n",
    "        utterance = utterance_prior()\n",
    "        literal_marginal = literal_listener(utterance)\n",
    "        projected_literal = project(literal_marginal, qud)\n",
    "        pyro.sample(\"listener\", projected_literal, obs=qudValue)\n",
    "    return utterance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible QUDs capture that the speaker may be attending to the price, the rough approximate price, her affect, or some combination of these. We assume a uniform QUD prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A helper to round a number to the nearest ten:\n",
    "def approx(x, b=None):\n",
    "    if b is None:\n",
    "        b = 10.\n",
    "    div = float(x)/b\n",
    "    rounded = int(div) + 1 if div - float(int(div)) >= 0.5 else int(div)\n",
    "    return int(b) * rounded\n",
    "\n",
    "#The QUD functions we consider:\n",
    "qud_fns = {\n",
    "    \"price\": lambda state: State(price=state.price, arousal=None),\n",
    "    \"arousal\": lambda state: State(price=None, arousal=state.arousal),\n",
    "    \"priceArousal\": lambda state: State(price=state.price, arousal=state.arousal),\n",
    "    \"approxPrice\": lambda state: State(price=approx(state.price), arousal=None),\n",
    "    \"approxPriceArousal\": lambda state: State(price=approx(state.price), arousal=state.arousal),\n",
    "}\n",
    "\n",
    "def qud_prior():\n",
    "    values = qud_fns.keys()\n",
    "    ix = pyro.sample(\"qud\", dist.Categorical(probs=torch.ones(len(values)) / len(values)))\n",
    "    return values[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the utterance meanings (standard number word denotations: \"N\" means exactly $N$) and an utterance prior that slightly favors multiples of ten (since they are easier to say). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_cost(numberUtt):\n",
    "    preciseNumberCost = 1.\n",
    "    return 0. if approx(numberUtt) == numberUtt else preciseNumberCost\n",
    "\n",
    "def utterance_prior():\n",
    "    utterances = [50, 51, 500, 501, 1000, 1001, 5000, 5001, 10000, 10001]\n",
    "    utteranceLogits = -torch.tensor(list(map(utterance_cost, utterances)),\n",
    "                                    dtype=torch.float64)\n",
    "    ix = pyro.sample(\"utterance\", dist.Categorical(logits=utteranceLogits))\n",
    "    return utterances[ix]\n",
    "\n",
    "def meaning(utterance, price):\n",
    "    return utterance == price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's see what number term this speaker will say to express different states and QUDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(50, 0.05885342441754214), (51, 0.021650964885751123), (500, 0.14690170859972698), (501, 0.05404211846679762), (1000, 0.16569103067188898), (1001, 0.06095432377069485), (5000, 0.1766530142302777), (5001, 0.06498701215628543), (10000, 0.18295940071056901), (10001, 0.06730700209046614)]\n"
     ]
    }
   ],
   "source": [
    "def show_dist(d):\n",
    "    print([(s, d.log_prob(s).exp().item())\n",
    "       for s in d.enumerate_support()])\n",
    "\n",
    "show_dist( speaker(State(price=51, arousal=True), \"arousal\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different values above! When will the speaker favor non-literal utterances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the pragmatic listener doesn't know what the QUD is and so jointly reasons abut this and the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Marginal\n",
    "def pragmatic_listener(utterance):\n",
    "    state = state_prior()\n",
    "    qud = qud_prior()\n",
    "    speaker_marginal = speaker(state, qud)\n",
    "    pyro.sample(\"speaker\", speaker_marginal, obs=utterance)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this listener interpret the uttered price \"10,000\"? On the one hand this is a very unlikely price *a priori*, on the other if it were true it would come with strong arousal. Altogether this becomes a plausible *hyperbolic* utterence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(State(price=50, arousal=False), 0.020944558617174744), (State(price=50, arousal=True), 0.18962994295418753), (State(price=51, arousal=False), 0.01925106279557203), (State(price=51, arousal=True), 0.1742972008366076), (State(price=500, arousal=False), 0.000808846021274365), (State(price=500, arousal=True), 0.059996129350093005), (State(price=501, arousal=False), 0.0008164336950199049), (State(price=501, arousal=True), 0.06055894482242036), (State(price=1000, arousal=False), 0.00017359794987375894), (State(price=1000, arousal=True), 0.028312162297699544), (State(price=1001, arousal=False), 0.00016425635615857894), (State(price=1001, arousal=True), 0.026788637869123784), (State(price=5000, arousal=False), 3.889558295405094e-05), (State(price=5000, arousal=True), 0.015160315922876049), (State(price=5001, arousal=False), 3.854830096338977e-05), (State(price=5001, arousal=True), 0.015024955959278942), (State(price=10000, arousal=False), 0.0030440475496016244), (State(price=10000, arousal=True), 0.23182161303428866), (State(price=10001, arousal=False), 0.0018655171404222321), (State(price=10001, arousal=True), 0.1512643329444099)]\n"
     ]
    }
   ],
   "source": [
    "show_dist( pragmatic_listener(10000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irony and More Complex Affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
