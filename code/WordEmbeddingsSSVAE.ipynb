{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to read emotions in words using a Semi-Supervised Variational Autoencoder\n",
    "\n",
    "In this example, we use a semi-supervised variant of the VAE to train the model with emotion ratings as well.\n",
    "\n",
    "This example is adapted from the Pyro [SSVAE Tutorial](http://pyro.ai/examples/ss-vae.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference from the normal VAE is that now there is an additional observed **Emotion Ratings**. The parameters $\\theta$ now parameterize the transformation from **ratings** and $z$ to **word embeddings** $p_{\\theta}(\\text{embedding}| \\text{ rating}, z)$.\n",
    "\n",
    "One way to think about this model, coming from the VAE, is that the addition of the emotion ratings will encourage the model to learn $\\theta$ that reflect variance in the word embeddings due to emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a **semi-supervised variant of the VAE**, or SSVAE (Kingma et al, 2014; Siddharth et al, 2017).\n",
    "We discuss the SSVAE formulation at a high level, below, and we invite the interested reader to check the reference list at the bottom for the more theoretical details of inference in the SSVAE.) \n",
    "\n",
    "We will be using the same Dataset as before: we have a set of (Face, Rating) paired observations (with ~18 unique faces) and a set of 203 unlablled Faces we used for the VAE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised VAE\n",
    "\n",
    "The model is similar to the VAE in that there are `encoders` and `decoders`. The main difference is that, in addition to the `decoder`, there are now 2 `encoders`:\n",
    "\n",
    "- `decoder` \"goes from\" the (latent $z$ and ratings) to word embeddings, i.e. $p_\\theta(\\text{embedding }|z, \\text{ratings})$)\n",
    "- `encoder_y` \"goes from\" the embedding to the ratings, i.e., $q(\\text{ratings } | \\text{ embedding})$\n",
    "- `encoder_z` \"goes from\" (embedding and ratings) to the latent $z$, i.e., $q(z, | \\text{ ratings, embedding})$\n",
    "\n",
    "In our SSVAE model, we have a ``.model()`` and ``.guide()`` that are similar to the VAE: they define the reconstruction loss that the model is trained against (Kingma & Welling, 2014). \n",
    "\n",
    "We add an additional ``.model_rating()`` and ``.guide_rating()`` to add a \"supervised\" loss to guide the model to learn from the supervised examples (Kingma et al, 2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class SemiSupervisedVAE():\n",
    "    def model(self, emotion, embedding):\n",
    "        # condition on the observed data\n",
    "        emo = pyro.sample(\"emo\", Normal(emo_prior_loc, emo_prior_scale), obs=emotion)\n",
    "        # sample z given priors\n",
    "        z = pyro.sample(\"z\", dist.Normal(prior_location, prior_scale))\n",
    "        # generate the face using emotion and z, and condition on observed image\n",
    "        loc = self.decoder(torch.cat((z, emo), 1))           \n",
    "        pyro.sample(\"word\", dist.Bernoulli(loc), obs=embedding)\n",
    "        \n",
    "    def model_rating(self, embedding, emotion=None):\n",
    "        # Extra term to yield an auxiliary loss that we do gradient descent on\n",
    "        if emotion is not None:\n",
    "            emo_mean, emo_scale = self.encoder_y(embedding)\n",
    "            pyro.sample(\"emo_aux\", dist.Normal(emo_mean, emo_scale), obs=emotion)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preamble\n",
    "\n",
    "This first chunk of code imports the necessary python packages and functions that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import division, print_function, absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "\n",
    "\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torchvision.transforms import ToPILImage\n",
    "from skimage import io, transform\n",
    "from scipy.special import expit\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from pyro.contrib.examples.util import print_and_log, set_seed\n",
    "import pyro.poutine as poutine\n",
    "# custom helperCode for this tutorial, in helperCode.py\n",
    "import helperCode\n",
    "from utils.custom_mlp import MLP, Exp\n",
    "\n",
    "\n",
    "from visdom import Visdom\n",
    "\n",
    "#from utils.vae_plots import plot_llk, plot_vae_samples\n",
    "from utils.mnist_cached import  mkdir_p, setup_data_loaders\n",
    "from utils.vae_plots import plot_conditional_samples_ssvae, plot_vae_samples\n",
    "\n",
    "EMBED_SIZE = 50\n",
    "IMG_WIDTH = 100\n",
    "IMG_SIZE = IMG_WIDTH*IMG_WIDTH*3\n",
    "BATCH_SIZE = 32\n",
    "DEFAULT_HIDDEN_DIMS = [100, 100] # [200,200] #[500, 500]\n",
    "DEFAULT_Z_DIM = 10 # 50 #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word embeddings\n",
    "\n",
    "Now we will load the GloVe word embeddings. (Warning: may take up to a minute...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = os.path.join(os.path.abspath('..'), \"glove\", \"glove.6B.50d.txt\")\n",
    "\n",
    "# Whether or not to normalize the word vectors\n",
    "normalize_embeddings = False\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.sqrt(v.dot(v))\n",
    "    return v / norm\n",
    "\n",
    "def cosine_sim_np(a, b):\n",
    "    if normalize_embeddings:\n",
    "        return np.dot(a, b)\n",
    "    else:\n",
    "        return np.dot(normalize(a), normalize(b))\n",
    "\n",
    "def load_glove_embeddings(path):\n",
    "    print(\"Loading GloVe embeddings\")\n",
    "    with open(path,'r') as f:\n",
    "        model = {}\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]], dtype=np.float32)\n",
    "            if normalize_embeddings:\n",
    "                embedding = normalize(embedding)\n",
    "            model[word] = embedding\n",
    "        print(\"Done.\",len(model),\" words loaded!\")\n",
    "        return model\n",
    "\n",
    "embeddings = load_glove_embeddings(embed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "We will using dataset with only utterances and emotion ratings. Here are the utterances used in the experiment:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "dataset_path = os.path.join(os.path.abspath(\"..\"), \"CognitionData\", \"dataSecondExpt_utteranceOnly.csv\")\n",
    "expdata = pd.read_csv(dataset_path)\n",
    "\n",
    "# Print utterances\n",
    "utterances = list(sorted(pd.unique(expdata.loc[:][\"utterance\"])))\n",
    "print(utterances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk defines a function to read in the data, and stores the data in `word_emotion_dataset`. Each observation consists of a 8-dimensional emotion rating vector and an accompanying word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmotionDataset(Dataset):\n",
    "    \"\"\"Word emotion dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, embeddings, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the experiment csv file \n",
    "            embeddings (dict): Dictionary of pre-trained word embeddings.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.expdata = pd.read_csv(csv_file)\n",
    "        self.embeddings = embeddings\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.expdata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and normalize the emotion data\n",
    "        emotions = np.array(self.expdata.iloc[idx][\"happy\":\"disapp\"], np.float32)\n",
    "        emotions = (emotions-1)/8\n",
    "        \n",
    "        word = self.expdata.iloc[idx][\"utterance\"]\n",
    "        try:\n",
    "            embed = self.embeddings[word]\n",
    "            if self.transform:\n",
    "                embed = self.transform(embed)\n",
    "        except:\n",
    "            print(word)\n",
    "            raise\n",
    "\n",
    "        return word, embed, emotions\n",
    "\n",
    "# Transform to Tensor for use by PyTorch\n",
    "data_transform = torch.from_numpy\n",
    "\n",
    "# Read in datafile.\n",
    "print(\"Reading in dataset...\")\n",
    "\n",
    "word_emotion_dataset = WordEmotionDataset(csv_file=dataset_path, \n",
    "                                          embeddings=embeddings, \n",
    "                                          transform=data_transform)\n",
    "word_emotion_loader = torch.utils.data.DataLoader(word_emotion_dataset,\n",
    "                                                  batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                                  num_workers=4)\n",
    "\n",
    "N_samples = len(word_emotion_dataset)\n",
    "print(\"Number of observations:\", N_samples)\n",
    "\n",
    "# Taking a sample observation\n",
    "word1, embed1, emo1 = word_emotion_dataset[np.random.randint(0, N_samples)]\n",
    "print(\"Sample Observation: \")\n",
    "print(\"Utterance:\", word1)\n",
    "print(\"Embedding:\")\n",
    "print(embed1)\n",
    "print(\"Ratings:\")\n",
    "row_fmt =\"{:<8} \" * len(emo1)\n",
    "print(row_fmt.format(*helperCode.EMOTION_VAR_NAMES))\n",
    "print(row_fmt.format(*emo1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load dataset of additional exclamation words for unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    \"\"\"Random word dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, embeddings, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (int): Number of random words to use \n",
    "            embeddings (dict): Dictionary of pre-trained word embeddings.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.words = pd.read_csv(csv_file, header=None)\n",
    "        self.embeddings = embeddings\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load and normalize the emotion data        \n",
    "        word = self.words.iloc[idx][0]\n",
    "        try:\n",
    "            embed = self.embeddings[word]\n",
    "            if self.transform:\n",
    "                embed = self.transform(embed)\n",
    "        except:\n",
    "            print(word)\n",
    "            raise\n",
    "\n",
    "        return word, embed, 0\n",
    "\n",
    "exclamations_path = os.path.join(os.path.abspath(\"..\"), \"CognitionData\", \"exclamations.csv\")\n",
    "more_words_dataset = WordDataset(csv_file=exclamations_path, \n",
    "                                 embeddings=embeddings,\n",
    "                                 transform=data_transform)\n",
    "more_words_loader = torch.utils.data.DataLoader(more_words_dataset,\n",
    "                                                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Number of observations:\", len(more_words_dataset))\n",
    "\n",
    "# Taking a sample observation\n",
    "word2, embed2, _ = more_words_dataset[np.random.randint(0, len(more_words_dataset))]\n",
    "print(\"Sample Observation: \")\n",
    "print(\"Utterance:\", word2)\n",
    "print(\"Embedding:\")\n",
    "print(embed2)\n",
    "\n",
    "# Define dictionary of data loaders\n",
    "data_loaders = {\"supervised\": word_emotion_loader , \"unsupervised\": more_words_loader }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    This class encapsulates the parameters (neural networks), models & guides needed to train a\n",
    "    semi-supervised variational auto-encoder.\n",
    "    Modified from https://github.com/uber/pyro/blob/dev/examples/vae/ss_vae_M2.py\n",
    "\n",
    "    :param output_size: size of the tensor representing the ratings \n",
    "                        in our case, emotion ratings is an 8 dimensional vector in [0,1]\n",
    "                        global constant: helperCode.EMOTION_VAR_DIM (= 8)\n",
    "    :param input_size: size of the tensor representing the word embedding\n",
    "                        defaults to 300 (the largest size in GloVe)\n",
    "    :param z_dim: size of the tensor representing the latent random variable z\n",
    "    :param hidden_layers: a tuple (or list) of MultiLayer Perceptron (MLP) layers \n",
    "                          to be used in the neural networks\n",
    "                          representing the parameters of the distributions in our model\n",
    "    :param use_cuda: use GPUs for faster training\n",
    "    :param aux_loss_multiplier: the multiplier to use with the auxiliary loss\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size=helperCode.EMOTION_VAR_DIM, input_size=EMBED_SIZE, \n",
    "                 z_dim=DEFAULT_Z_DIM, hidden_layers=DEFAULT_HIDDEN_DIMS,\n",
    "                 config_enum=None, use_cuda=False, aux_loss_multiplier=None):\n",
    "        super(SSVAE, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.allow_broadcast = config_enum == 'parallel'\n",
    "        self.use_cuda = use_cuda\n",
    "        self.aux_loss_multiplier = aux_loss_multiplier\n",
    "        \n",
    "        # define the neural networks used later in the model and the guide.\n",
    "        # these networks are MLPs (multi-layered perceptrons or simple feed-forward networks)\n",
    "        # where the provided activation parameter is used on every linear layer except\n",
    "        # for the output layer where we use the provided output_activation parameter\n",
    "        \n",
    "        # self.encoder_y = nn.Sequential(\n",
    "        #       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        # a split in the final layer's size is used for multiple outputs\n",
    "        # and potentially applying separate activation functions on them\n",
    "        # e.g. in this network the final output is of size [z_dim, z_dim]\n",
    "        # to produce a mean and scale parameter for a Normal distribution, \n",
    "        # and we can apply different activations [None, Exp] on them\n",
    "\n",
    "        # encoder_y goes from embeddings to ratings\n",
    "        self.encoder_y = MLP([self.input_size] +\n",
    "                             self.hidden_layers + \n",
    "                             [[self.output_size, self.output_size]],\n",
    "                             activation=nn.Tanh,\n",
    "                             output_activation=[None, Exp],\n",
    "                             allow_broadcast=self.allow_broadcast,\n",
    "                             use_cuda=self.use_cuda)\n",
    "\n",
    "        # encoder_z goes from [embeddings, ratings] to z\n",
    "        self.encoder_z = MLP([self.input_size + self.output_size] +\n",
    "                             self.hidden_layers + [[z_dim, z_dim]],\n",
    "                             activation=nn.ReLU,\n",
    "                             output_activation=[None, Exp],\n",
    "                             allow_broadcast=self.allow_broadcast,\n",
    "                             use_cuda=self.use_cuda)\n",
    "\n",
    "        # decoder goes from [z, emotion ratings] to the embedding.\n",
    "        self.decoder = MLP([z_dim + self.output_size] +\n",
    "                           self.hidden_layers[::-1] +\n",
    "                           [[self.input_size, self.input_size]],\n",
    "                           activation=nn.ReLU,\n",
    "                           output_activation=nn.Sigmoid,\n",
    "                           allow_broadcast=self.allow_broadcast,\n",
    "                           use_cuda=self.use_cuda)\n",
    "        \n",
    "        # using GPUs for faster training of the networks\n",
    "        if self.use_cuda:\n",
    "            self.cuda()\n",
    "            \n",
    "    def model(self, xs, ys=None, beta=1.0):\n",
    "        \"\"\"\n",
    "        The model corresponds to the following generative process:\n",
    "        p(z)     = normal(0,I)              # Prior on the latent variable z\n",
    "        p(y)     = normal(.5, .05)          # Emotion Rating corresponding to word embedding\n",
    "        p(x|y,z) = normal(decoder(y,z))  # Producing an image\n",
    "                                              decoder is a neural network\n",
    "\n",
    "        :param xs: a batch of word embeddings\n",
    "        :param ys: (optional) a batch of emotion ratings.\n",
    "                   if ys is not provided, will treat as unsupervised, sample from prior.\n",
    "        :param beta: scale parameter that weights the KL divergence in the ELBO\n",
    "                     also sometimes called annealing.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"ssvae\", self)\n",
    "\n",
    "        batch_size = xs.size(0)\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.iarange(\"data\"):\n",
    "\n",
    "            # sample the latent z from the (constant) prior, z ~ Normal(0,I)\n",
    "            z_prior_mean  = torch.zeros(size=[batch_size, self.z_dim])\n",
    "            z_prior_scale = torch.exp(torch.zeros(size=[batch_size, self.z_dim]))\n",
    "            with poutine.scale(scale=beta):\n",
    "                zs = pyro.sample(\"z\", dist.Normal(z_prior_mean, z_prior_scale).independent(1))\n",
    "\n",
    "            # if the label y (emotion rating) is not provided, sample from the\n",
    "            # constant prior, otherwise, observe the value (i.e. score it against the constant prior)\n",
    "            y_prior_mean  = torch.ones(size=[batch_size, self.output_size]) *0.5 #/ (1.0 * self.output_size)\n",
    "            y_prior_scale = torch.ones(size=[batch_size, self.output_size]) *0.05\n",
    "            if ys is None:\n",
    "                ys = pyro.sample(\"y\", dist.Normal(y_prior_mean, y_prior_scale).independent(1))\n",
    "            else:\n",
    "                ys = pyro.sample(\"y\", dist.Normal(y_prior_mean, y_prior_scale).independent(1), obs=ys)\n",
    "                \n",
    "            # Finally, we can condition on observing the word embedding,\n",
    "            #    using the latent z and emotion rating y in the \n",
    "            #    parametrized distribution p(x|y,z) = bernoulli(decoder(y,z))\n",
    "            #    where decoder is a neural network\n",
    "            \n",
    "            x_mean, x_scale = self.decoder.forward([zs, ys])\n",
    "            pyro.sample(\"x\", dist.Normal(x_mean, x_scale).independent(1), obs=xs)\n",
    "            \n",
    "            # return the mean and variance of the word embedding distribution\n",
    "            return x_mean, x_scale\n",
    "\n",
    "    def guide(self, xs, ys=None, beta=1.0):\n",
    "        \"\"\"\n",
    "        The guide corresponds to the following:\n",
    "        q(y|x)   = normal(encoder_y(x))   # infer emotion rating from word embedding\n",
    "        q(z|x,y) = normal(encoder_z(x,y)) # infer z from embedding and the emotion rating\n",
    "\n",
    "        :param xs: a batch of word vectors\n",
    "        :param ys: (optional) a batch of emotion ratings.\n",
    "                   if ys is not provided, will treat as unsupervised\n",
    "        :param beta: not used here, but left to match the call signature of self.model()\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.iarange(\"data\"):\n",
    "\n",
    "            # if the emotion rating is not provided, \n",
    "            #    sample with the variational distribution\n",
    "            #    q(y|x) = Normal(encoder_y(x))\n",
    "            if ys is None:\n",
    "                y_mean, y_scale = self.encoder_y.forward(xs)\n",
    "                #scale_ys = xs.new_ones([batch_size, self.output_size])*0.05\n",
    "                ys = pyro.sample(\"y\", dist.Normal(y_mean, y_scale).independent(1))\n",
    "                \n",
    "            # Sample (and score) the latent z with the variational\n",
    "            #   distribution q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "            #   where loc(.), scale(.) are given by encoder_z()\n",
    "                        \n",
    "            z_mean, z_scale = self.encoder_z.forward([xs, ys])\n",
    "            with poutine.scale(scale=beta): \n",
    "                pyro.sample(\"z\", dist.Normal(z_mean, z_scale).independent(1))\n",
    "\n",
    "    def model_rating(self, xs, ys=None, beta=None):\n",
    "        \"\"\"\n",
    "        this model is used to add an auxiliary (supervised) loss as described in\n",
    "        Kingma et al. (2014), \"Semi-Supervised Learning with Deep Generative Models\".\n",
    "        \n",
    "        This is to ensure that the model learns from the supervised examples.\n",
    "        q(y|x) = normal(encoder_y(x))\n",
    "        \n",
    "        :param xs:   word embedding\n",
    "        :param ys:   emotion rating\n",
    "        :param beta: not used here, but left to match the call signature of self.model()\n",
    "        \"\"\"\n",
    "        # register all pytorch (sub)modules with pyro\n",
    "        pyro.module(\"ssvae\", self)\n",
    "\n",
    "        # inform Pyro that the variables in the batch of xs, ys are conditionally independent\n",
    "        with pyro.iarange(\"data\"):\n",
    "            # this is the extra term to yield an auxiliary loss that we do gradient descent on\n",
    "            if ys is not None:\n",
    "                y_mean, y_scale = self.encoder_y.forward(xs)\n",
    "                with pyro.poutine.scale(scale=self.aux_loss_multiplier):\n",
    "                    pyro.sample(\"y_aux\", dist.Normal(y_mean, y_scale).independent(1), obs=ys)\n",
    "\n",
    "    def guide_rating(self, xs, ys=None, beta=None):\n",
    "        \"\"\"\n",
    "        dummy guide function to accompany model_rating() in inference\n",
    "        This guide function is empty, because model_rating() has no latent random variables\n",
    "        (i.e., model_rating() has no pyro.sample() calls that are not conditioned on observations)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    # define a helper function to assign ratings to faces\n",
    "    def rate(self, xs):\n",
    "        \"\"\"\n",
    "        assign emotion ratings (ys) to a word embedding (or a batch of them)\n",
    "\n",
    "        :param xs: a batch of word vectors\n",
    "        :return:   a batch of the corresponding emotion ratings (ys)\n",
    "        \"\"\"\n",
    "        # use the trained model q(y|x) = normal(encoder_y(x))\n",
    "        # compute the emotion ratings for the image(s)\n",
    "        y_mean, y_scale = self.encoder_y.forward(xs)\n",
    "        return y_mean\n",
    "    \n",
    "    # define a helper function for reconstructing word vectors\n",
    "    def reconstruct_word(self, x):\n",
    "        # encode word vector x. This function assumes that x is a single vector, \n",
    "        # but as the encoders and decoders take in batches, we have to resize x:\n",
    "        xs = x.view(1, EMBED_SIZE)\n",
    "        y_mean, y_scale = self.encoder_y.forward(xs)\n",
    "        ys = dist.Normal(y_mean, y_scale).sample()\n",
    "        z_mean, z_scale = self.encoder_z.forward([xs, ys])\n",
    "        # sample in latent space\n",
    "        zs = dist.Normal(z_mean, z_scale).sample()\n",
    "        # decode the word (note we don't sample in the word embedding space)\n",
    "        x_mean, x_scale = self.decoder([zs, ys])\n",
    "        return x_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Next we define the parameters of our training session, and set up the model and inference algorithm. This part is identical to the linear regression and VAE example.\n",
    "\n",
    "The key difference is that we have 2 losses. \n",
    "\n",
    "- The unsupervised loss from the vanilla VAE, which is captured by ```loss_basic = SVI(ssvae.model, ssvae.guide, optimizer, loss=Trace_ELBO())``` \n",
    "- and the supervised loss, or auxillary loss, captured by ```loss_aux = SVI(ssvae.model_rating, ssvae.guide_rating, optimizer, loss=Trace_ELBO())```\n",
    "\n",
    "At each loop in the training, we take one \"basic\" step and one \"auxillary\" step, to train the model with both losses together.\n",
    "\n",
    "`num_epochs` below is set to 1000. If you just want to check if the code works, set it to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    learning_rate = 5e-5 # 5e-6\n",
    "    num_epochs = 1000 #1\n",
    "    hidden_layers = DEFAULT_HIDDEN_DIMS\n",
    "    z_dim = DEFAULT_Z_DIM\n",
    "    seed = 1\n",
    "    beta_1 = 0.900\n",
    "    aux_loss = True \n",
    "    aux_loss_multiplier = 10 #50.0\n",
    "    cuda = False\n",
    "    # enum_discrete = None #\"parallel\"#\"sequential\" #\"parallel\"\n",
    "    #visdom_flag = True\n",
    "    #visualize = True\n",
    "    #logfile = \"./tmp.log\"\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "unsup_num = len(more_words_dataset)\n",
    "sup_num = len(word_emotion_dataset)\n",
    "\n",
    "\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed, args.cuda)\n",
    "\n",
    "# batch_size: number of images (and labels) to be considered in a batch\n",
    "ssvae = SSVAE(output_size=helperCode.EMOTION_VAR_DIM, input_size=EMBED_SIZE, \n",
    "              z_dim=args.z_dim,\n",
    "              hidden_layers=args.hidden_layers,\n",
    "              use_cuda=args.cuda,\n",
    "              #config_enum=args.enum_discrete,\n",
    "              aux_loss_multiplier=args.aux_loss_multiplier)\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": args.learning_rate, \"betas\": (args.beta_1, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# set up the loss(es) for inference. \n",
    "\n",
    "## wrapping the guide in config_enumerate builds the loss as a sum\n",
    "## by enumerating each class label for the sampled discrete categorical distribution in the model\n",
    "##guide = config_enumerate(ssvae.guide, args.enum_discrete)\n",
    "##loss_basic = SVI(ssvae.model, guide, optimizer, loss=TraceEnum_ELBO(max_iarange_nesting=2))\n",
    "\n",
    "loss_basic = SVI(ssvae.model, ssvae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# build a list of all losses considered\n",
    "losses = [loss_basic]\n",
    "\n",
    "# aux_loss: whether to use the auxiliary loss from (Kingma et al, 2014 NIPS paper)\n",
    "if args.aux_loss:\n",
    "    loss_aux = SVI(ssvae.model_rating, ssvae.guide_rating, optimizer, loss=Trace_ELBO())\n",
    "    losses.append(loss_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Inference\n",
    "\n",
    "This next chunk defines some helper functions to help run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeta(epoch, gamma=1e-2, c=800):\n",
    "    # this is a helper function to compute an annealing parameter beta for a given epoch.\n",
    "    # beta starts off near 0 and gradually increases, reaching 1 at epoch=c\n",
    "    return float(expit(gamma*(epoch - c)))\n",
    "\n",
    "def run_inference_for_epoch(data_loaders, losses, epoch, gamma=1e-2, c=800, cuda=False):\n",
    "    \"\"\"\n",
    "    runs the inference algorithm for an epoch\n",
    "    returns the values of all losses separately on supervised and unsupervised parts\n",
    "    \"\"\"\n",
    "    num_losses = len(losses)\n",
    "\n",
    "    # compute number of batches for an epoch\n",
    "    # don't use all the sup_batches\n",
    "    sup_batches = len(data_loaders[\"supervised\"])\n",
    "    unsup_batches = len(data_loaders[\"unsupervised\"])\n",
    "    batches_per_epoch = sup_batches + unsup_batches\n",
    "\n",
    "    # initialize variables to store loss values\n",
    "    epoch_losses_sup = [0.] * num_losses\n",
    "    epoch_losses_unsup = [0.] * num_losses\n",
    "\n",
    "    # setup the iterators for training data loaders\n",
    "    sup_iter = iter(data_loaders[\"supervised\"])\n",
    "    unsup_iter = iter(data_loaders[\"unsupervised\"])\n",
    "\n",
    "    # random order\n",
    "    is_sups = [1]*sup_batches + [0]*unsup_batches\n",
    "    is_sups = np.random.permutation(is_sups)\n",
    "    \n",
    "    # annealing factor\n",
    "    beta = getBeta(epoch, gamma, c)\n",
    "    \n",
    "    for i in range(batches_per_epoch):\n",
    "        #if i%10 == 0:\n",
    "        #    print(\"Epoch\", epoch, \": on batch\", i, \"out of\", batches_per_epoch)\n",
    "        # whether this batch is supervised or not\n",
    "        is_supervised = is_sups[i]\n",
    "        \n",
    "        # extract the corresponding batch\n",
    "        if is_supervised:\n",
    "            _, xs, ys = next(sup_iter)\n",
    "        else:\n",
    "            _, xs, ys = next(unsup_iter)\n",
    "            \n",
    "        if cuda:\n",
    "            ys = ys.cuda()\n",
    "            xs = xs.cuda()\n",
    "        \n",
    "        batchsize = xs.size(0)\n",
    "        xs = xs.view(batchsize, -1)\n",
    "        \n",
    "        # run the inference for each loss with supervised or un-supervised\n",
    "        # data as arguments\n",
    "        for loss_id in range(num_losses):\n",
    "            if is_supervised:\n",
    "                new_loss = losses[loss_id].step(xs, ys, beta=beta)\n",
    "                epoch_losses_sup[loss_id] += new_loss\n",
    "            else:\n",
    "                new_loss = losses[loss_id].step(xs, beta=beta)\n",
    "                epoch_losses_unsup[loss_id] += new_loss\n",
    "\n",
    "    # return the values of all losses\n",
    "    return epoch_losses_sup, epoch_losses_unsup\n",
    "\n",
    "def get_prediction_error(data_loader, rating_fn):\n",
    "    \"\"\"\n",
    "    compute the prediction error over the supervised training set or the testing set\n",
    "    \"\"\"\n",
    "    predictions, actuals = [], []\n",
    "\n",
    "    # use the appropriate data loader\n",
    "    for (_, xs, ys) in data_loader:\n",
    "        # use classification function to compute all predictions for each batch\n",
    "        batchsize = xs.size(0)\n",
    "        xs = xs.view(batchsize, -1)\n",
    "        ys = ys.view(batchsize, -1)\n",
    "        predictions.append(rating_fn(xs))\n",
    "        actuals.append(ys)\n",
    "        \n",
    "    #abs(predictions[i] - actuals[i]) for i in range(len(predictions))\n",
    "\n",
    "    predErrors = [abs(pred_i - act_i) for pred_i, act_i in zip(predictions, actuals)]\n",
    "    meanPredError = sum([torch.sum(pe) for pe in predErrors]) / (len(predictions) * BATCH_SIZE * helperCode.EMOTION_VAR_DIM)\n",
    "\n",
    "    return meanPredError, predictions, actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "\n",
    "This next chunk of code runs the training over `num_epochs` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # run inference for a certain number of epochs\n",
    "    for i in range(0, args.num_epochs):\n",
    "\n",
    "        # get the losses for an epoch\n",
    "        epoch_losses_sup, epoch_losses_unsup = \\\n",
    "            run_inference_for_epoch(data_loaders, losses, epoch=i, cuda=args.cuda)\n",
    "\n",
    "        # compute average epoch losses i.e. losses per example\n",
    "        avg_epoch_losses_sup = map(lambda v: v / sup_num, epoch_losses_sup)\n",
    "        avg_epoch_losses_unsup = map(lambda v: v / unsup_num, epoch_losses_unsup)\n",
    "\n",
    "        # store the loss and validation/testing accuracies in the logfile\n",
    "        #str_loss_sup = \" \".join(map(str, avg_epoch_losses_sup))\n",
    "        #str_loss_unsup = \" \".join(map(str, avg_epoch_losses_unsup))\n",
    "        str_loss_sup = \"Supervised Recon Loss: \" + str(avg_epoch_losses_sup[0]) + \\\n",
    "        \"\\n     Auxillary Loss: \" + str(avg_epoch_losses_sup[1])\n",
    "        str_loss_unsup = \"\\n     Unsupervised Recon Loss: \" + str(avg_epoch_losses_unsup[0])\n",
    "\n",
    "        str_print = \"Epoch {} : Avg {}\".format(i, \"{} {}\".format(str_loss_sup, str_loss_unsup))\n",
    "        \n",
    "        predErr, _, _ = get_prediction_error(data_loaders[\"supervised\"], ssvae.rate)\n",
    "        str_print += \"\\n     Train set prediction error: {}\".format(predErr)\n",
    "        print(str_print)\n",
    "finally:\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the model above takes a while to train, you can use the following two chunks to save or load a model. We assume that you'll skip this save step and load the model from `trained_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "savemodel = True\n",
    "if savemodel:\n",
    "    pyro.get_param_store().save('word_ssvae_pretrained.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel = True\n",
    "if loadmodel:\n",
    "    pyro.get_param_store().load('word_ssvae_pretrained.save')\n",
    "    pyro.module(\"ssvae\", ssvae, update_module_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.get_param_store().get_all_param_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reconstruct the utterances and evaluate their predictions and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_torch(a, b):\n",
    "    a_norm = a / a.norm()\n",
    "    b_norm = b / b.norm()    \n",
    "    return torch.dot(a_norm, b_norm)\n",
    "\n",
    "# Flag whether to evaluate labelled or non-labelled examples\n",
    "eval_training = True\n",
    "\n",
    "## Use training set as samples\n",
    "if eval_training:\n",
    "    train_words = ['awesome', 'cool', 'damn', 'dang', 'man', 'meh', 'oh', 'wow', 'yay', 'yikes']\n",
    "    samples = []\n",
    "    df = word_emotion_dataset.expdata\n",
    "    for w in train_words:\n",
    "        # Lookup emotion ratings for each word\n",
    "        df_ratings = df[df['utterance']==w].loc[:,\"happy\":\"disapp\"]\n",
    "        # Average across all observations\n",
    "        ratings = df_ratings.mean(axis=0).values\n",
    "        # Normalize to [0,1]\n",
    "        ratings = (ratings - 1)/8\n",
    "        samples.append((w, torch.from_numpy(embeddings[w]), ratings))\n",
    "else:\n",
    "    ## Select samples randomly from corpus\n",
    "    NUM_SAMPLES = 10\n",
    "    indices = np.random.randint(0, len(more_words_dataset), NUM_SAMPLES)\n",
    "    samples = [more_words_dataset[i] for i in indices]\n",
    "\n",
    "# Number of nearest neighbors to the reconstructed vector to find\n",
    "k_neighbors = 3 # 0\n",
    "    \n",
    "print(\"Reconstruction similarity and ratings\")\n",
    "for word, embed, ratings in samples:\n",
    "    # Reconstruct the embedding\n",
    "    recon_embed = ssvae.reconstruct_word(embed).view(-1)\n",
    "    # Find cosine similarity\n",
    "    sim = cosine_sim_torch(embed, recon_embed).detach().numpy()\n",
    "    # Predict ratings\n",
    "    pred_ratings = ssvae.rate(embed).detach().numpy()\n",
    "\n",
    "    if k_neighbors > 0:\n",
    "        embed_np = recon_embed.detach().numpy()\n",
    "        nb_pairs = heapq.nlargest(k_neighbors, embeddings.iteritems(),\n",
    "                                  key=lambda x: cosine_sim_np(embed_np, x[1]))\n",
    "        nb_words, nb_embed = zip(*nb_pairs)\n",
    "        \n",
    "    # Print reconstruction similarity\n",
    "    print(\"{:8} : {:10}\".format(word, sim))\n",
    "    if k_neighbors > 0:\n",
    "        print(\"neighbors: \", nb_words)\n",
    "    str_row_fmt =\"{:<8.8} \" * len(pred_ratings)\n",
    "    print(str_row_fmt.format(*helperCode.EMOTION_VAR_NAMES))\n",
    "    num_row_fmt =\"{:<8.3f} \" * len(pred_ratings)\n",
    "    # Print average of observed raitings if evaluating training\n",
    "    if eval_training:\n",
    "        print(num_row_fmt.format(*ratings))        \n",
    "    print(num_row_fmt.format(*pred_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Written by: Desmond Ong (desmond.c.ong@gmail.com) and Harold Soh (hsoh@comp.nus.edu.sg)\n",
    "\n",
    "References:\n",
    "\n",
    "Pyro [VAE tutorial](http://pyro.ai/examples/vae.html), [SSVAE tutorial](http://pyro.ai/examples/ss-vae.html)\n",
    "\n",
    "Hoffman, M. D., Blei, D. M., Wang, C., & Paisley, J. (2013). Stochastic\n",
    "variational inference. *The Journal of Machine Learning Research*, 14(1),\n",
    "1303-1347.\n",
    "\n",
    "Kingma, D. P., Mohamed, S., Rezende, D. J., & Welling, M. (2014). Semi-supervised learning with deep generative models. In *Advances in Neural Information Processing Systems*, pp. 3581-3589. https://arxiv.org/abs/1406.5298\n",
    "\n",
    "Kingma, D. P., & Welling, M. (2014). Auto-encoding variational bayes. Auto-Encoding Variational Bayes. In *The International Conference on Learning Representations*. https://arxiv.org/abs/1312.6114\n",
    "\n",
    "\n",
    "Narayanaswamy, S., Paige, T. B., van de Meent, J. W., Desmaison, A., Goodman, N. D., Kohli, P., Wood, F. & Torr, P. (2017). Learning Disentangled Representations with Semi-Supervised Deep Generative Models. In *Advances in Neural Information Processing Systems*, pp. 5927-5937. https://arxiv.org/abs/1706.00400\n",
    "\n",
    "Data from https://github.com/desmond-ong/affCog, from the following paper:\n",
    "\n",
    "Ong, D. C., Zaki, J., & Goodman, N. D. (2015). Affective Cognition: Exploring lay theories of emotion. *Cognition*, 143, 141-162."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
