{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression as a model of Emotional Appraisal\n",
    "\n",
    "The first example we discuss involves building a simple linear regression model in Pyro. We consider a case that is relevant to affective computing --- how should we build a model to reason about someone's emotions? There are lots of emotion theories that one can draw from, and probabilistic programming offers an elegant way to specify (and test!) these theories.\n",
    "\n",
    "\n",
    "Before we jump in, we want to introduce the dataset that we'll be working with throughout the rest of the tutorial. This dataset is of a managable size (so training shouldn't take too long), but still complex enough that we can demonstrate some of the nice features of applying probabilistic programming to model real-life, AI-relevant examples (in this case, relevant to affective computing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will be using data from a published paper (Ong, Zaki, & Goodman, 2015; Experiment 3), which is available [here](https://github.com/desmond-ong/affCog) but we have also reproduced the data in the current repository. In this experiment, we showed human participants an agent playing a gamble; he spins a wheel with three possible outcomes, and wins the amount on the wheel. \n",
    "\n",
    "<div style=\"width: 500px; margin: auto;\">![Experiment Summary](images/experimentSummary.png)</div>\n",
    "(Figure modified from Ong et al, 2015, Figure 9).\n",
    "\n",
    "On some trials, participants see the outcome that the agent won ((i) above). On other trials ((ii) above), participants were not shown the outcome, but instead were shown what ostensibly was the agent's facial expression after seeing the outcome. And on the last third of trials ((iii) above), participants were shown both the outcome and the agent's facial expression.\n",
    "Following these, participants were asked to rate how they thought the agent felt, on 8 emotions, using a 9 point Likert scale.\n",
    "\n",
    "Thus, the dataset consists of some \"outcome only\" trials where participants saw outcomes and rated the agent's emotions, \"facial expression only\" trials where participants attributed emotions to a facial expression, and trials where they saw both and had to integrate the information from both the outcome and the facial expression to make a judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appraising the outcome\n",
    "\n",
    "Let us first consider the \"outcome only\" trials. Many established emotion theories and affective computing theories hold that people experiencing events (e.g., winning the lottery, missing the bus) will evaluate the situation according to a set of important features. Was the outcome desirable? Was the outcome surprising? Was the outcome controllable? This evaluation is known as **appraisal**.\n",
    "\n",
    "Put another way, the number of situations that people encounter in daily life vary immensely along a large number of dimensions, some important (the amount that one wins in the lottery) and some not so important (the color of the lottery ticket). **Appraisal** is computationally necessary to reduce the complexities of everyday situations into a low dimensional set of emotion-relevant dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Linear Regression model with Appraisal\n",
    "\n",
    "Thus, we already have the few basic ingreidents of our theory. We have an observable variable (the outcome). We have an appraisal process that converts the outcome into a small number of relevant features. And we have the emotion ratings that people produce. Let's construct a basic regression model:\n",
    "\n",
    "<div style=\"width: 300px; margin: auto;\">![Graphical Model](images/graphicalModel_LinearRegression.png)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to read the model above, which uses graphical mdoel notation. Shaded circles represent observed variables, while unshaded represents latent, or unobserved variables. Small rectangles represent parameters (to be fitted). We have $N$ pairs of (*Outcome*, *Emotion Ratings*), where $N$ is the size of the dataset, and so these are represented in the large rectangle (called a \"plate\"), to indicate that they are repeated $N$ times. And between these *Outcome* and *Rating* pairs, we have an appraisal transformation.\n",
    "\n",
    "In a linear regression, we have beta weights that map the appraisal to the emotion ratings. If the appraisal variables are given by $\\{1, a_1, a_2, \\ldots, a_I\\} = \\vec{a}$, we can write an equation like: \n",
    "\n",
    "*Rating* = $\\vec{\\beta} \\cdot \\vec{a}$ = $\\beta_0$ + $\\beta_1 a_1$ + $\\beta_2 a_2$ + $\\ldots$ + $\\beta_I a_I$ + $\\epsilon$\n",
    "\n",
    "where the $\\beta_i$s represent the regression weights for the $i$-th appraisal variable, $\\beta_0$ is the bias term and $\\epsilon$ is an error term. Notice that the $\\beta_i$s should remain the same across all $N$ observations: thus, it is left out of the \"plate\" in the model diagram above.\n",
    "\n",
    "We assume that each $\\beta_i$ is drawn from a Normal distribution parameterized by a mean (location parameter) $\\mu_i$ and a standard deviation (or scale parameter) $\\sigma_i$. I.e., $\\beta_i \\sim N(\\mu_i, \\sigma_i)$. We wish to learn these parameters $\\mu_i, \\sigma_i$ from the data.\n",
    "\n",
    "\n",
    "(Note: Appraisal in this model is a strange creature. We could represent it as a latent variable (so like *outcome*, but unshaded). Here, to reflect the fact that appraisal is a modular function that can be tested scientifically against data, we chose to represent it more like a fittable parameter.).\n",
    "\n",
    "Let's write some Pyro!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preamble\n",
    "\n",
    "This first chunk of code imports the necessary python packages and functions that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk defines some variable and names that are specific to this dataset, as well as a function to read in the data.\n",
    "\n",
    "The data is stored in `outcome_emotion_dataset`, which is a torch Tensor of size (1541, 17), indicating that there are N=1,541 observations of 17 variables. The first 9 are the parameterization of the outcome (the 3 payoffs on the wheel and their probabilities, which outcome they won and that probability, and the angle within the sector that the wheel landed on), and the next 8 are the emotion variables. All the variables are scaled so that they lie within [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1541, 17])\n"
     ]
    }
   ],
   "source": [
    "# data location\n",
    "dataset_path = os.path.join(os.path.abspath('..'), \"CognitionData\", \"data_wheelOnly.csv\")\n",
    "\n",
    "OUTCOME_VAR_NAMES = [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
    "EMOTION_VAR_NAMES = [\"happy\", \"sad\", \"anger\", \"surprise\", \"disgust\", \"fear\", \"content\", \"disapp\"]\n",
    "OUTCOME_VAR_DIM = len(OUTCOME_VAR_NAMES)\n",
    "EMOTION_VAR_DIM = len(EMOTION_VAR_NAMES)\n",
    "\n",
    "def load_outcome_emotion_dataset(csv_file, normalize_values=True):\n",
    "    data_readin = pd.read_csv(csv_file)\n",
    "    outcome_data = data_readin.loc[:,OUTCOME_VAR_NAMES]\n",
    "    if normalize_values:\n",
    "        ####\n",
    "        ## payoff1, payoff2, payoff3 and win are between 0 and 100\n",
    "        ## need to normalize to [0,1] to match the rest of the variables,\n",
    "        ## by dividing payoff1, payoff2, payoff3 and win by 100\n",
    "        ####\n",
    "        outcome_data.loc[:,\"payoff1\"] = outcome_data.loc[:,\"payoff1\"]/100\n",
    "        outcome_data.loc[:,\"payoff2\"] = outcome_data.loc[:,\"payoff2\"]/100\n",
    "        outcome_data.loc[:,\"payoff3\"] = outcome_data.loc[:,\"payoff3\"]/100\n",
    "        outcome_data.loc[:,\"win\"]     = outcome_data.loc[:,\"win\"]/100\n",
    "    outcome_data = torch.tensor(outcome_data.values).type(torch.Tensor)\n",
    "    \n",
    "    # the actual data has 8 emotions, but for illustration we just use 1 emotion, happy\n",
    "    # the rest of the functions below assume a 1-D \"y\" variable\n",
    "    emotion_data = data_readin.loc[:,EMOTION_VAR_NAMES]\n",
    "    #emotion_data = data_readin.loc[:, \"happy\"]\n",
    "    if normalize_values:\n",
    "        ## note that emotions are transformed from a 9 point Likert to [0,1] via emo <- (emo-1)/8\n",
    "        emotion_data   = (emotion_data-1)/8\n",
    "    #emotion_data = emotion_data.values.reshape( emotion_data.shape[0] , 1)\n",
    "    #emotion_data = torch.tensor(emotion_data).type(torch.Tensor)\n",
    "    emotion_data = torch.tensor(emotion_data.values).type(torch.Tensor)\n",
    "    \n",
    "    data = torch.cat((outcome_data, emotion_data), 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "# reads in datafile\n",
    "outcome_emotion_dataset = load_outcome_emotion_dataset(csv_file=dataset_path)\n",
    "N_samples = outcome_emotion_dataset.shape[0]\n",
    "\n",
    "print(outcome_emotion_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_appraisal()` is a function that takes in an outcome vector, and returns a vector of appraisal values. The example below reproduces the appraisal function used in Ong et al (2015). But more generally, this is a modular function that can be substituted out to test other possible operationalizations of appraisal theories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_appraisal(outcome_data):\n",
    "    # We have a simple hard-coded these appraisals, for illustration\n",
    "    # This is following Ong, Zaki, & Goodman (2015)\n",
    "    # the outcome data columns are, in order:\n",
    "    # [\"payoff1\", \"payoff2\", \"payoff3\", \"prob1\", \"prob2\", \"prob3\", \"win\", \"winProb\", \"angleProp\"]\n",
    "    # the 3 appraisal variables are: \n",
    "    #     amount won (\"win\"),\n",
    "    #     Prediction Error PE = win - EV, where EV = prob1*payoff1 + prob2*payoff2 + prob3*payoff3\n",
    "    #     absolute value of PE\n",
    "    \n",
    "    # if outcome_data only has 1 observation, reshape so vectorization works\n",
    "    if(len(outcome_data.shape)==1):\n",
    "        outcome_data = outcome_data.view(1,9)\n",
    "        print(outcome_data.shape)\n",
    "    \n",
    "    # initializing appraisalVals\n",
    "    appraisalVals = torch.zeros(size=(outcome_data.shape[0],3))\n",
    "    appraisalVals[:,0] = outcome_data[:,6] # amount won\n",
    "    \n",
    "    # Expected value\n",
    "    EV = outcome_data[:,0] * outcome_data[:,3] + \\\n",
    "         outcome_data[:,1] * outcome_data[:,4] + \\\n",
    "         outcome_data[:,2] * outcome_data[:,5]\n",
    "    \n",
    "    # prediction error and absolute PE\n",
    "    appraisalVals[:,1] = appraisalVals[:,0] - EV\n",
    "    appraisalVals[:,2] = abs(appraisalVals[:,1])\n",
    "    return(appraisalVals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model. Let's break down what goes on.\n",
    "\n",
    "First, the model samples some $\\beta$ coefficients from a Normal with some priors over the mean and the scale (in this case, mean of 0 and scale of 1).\n",
    "This is achieved using the `pyro.sample()` function. \n",
    "For example,\n",
    "\n",
    "`b_0 = pyro.sample(\"b_0\", Normal(coeff_mean_prior, coeff_scale_prior))`\n",
    "\n",
    "\n",
    "Note that the `sample()` function takes in a variable name, which allows Pyro to uniquely identify that variable in its variable store. (As such, the variable names are unique, and you can only have one `sample()` function with a particular variable name in this function).\n",
    "\n",
    "\n",
    "\n",
    "Next, the function will loop over the observed data, using `pyro.iarange()`. This function defines a special Pyro environment with a unique name (`\"map\"`), within which Pyro understands that each iteration of the \"loop\" is conditionally independent. Thus, the computation on each data-point is conditionally independent from the computation on other data-points. (This reflects the plate-notation in the model above; each datapoint is independent, BUT the $\\beta$ coefficients are the same across all of them, that's why they were defined before the `pyro.iarange()` loop)\n",
    "\n",
    "Within this loop, we take the `outcome_data`, run it through `compute_appraisal()` to get a small 3-dimensional `appraisal_vars`. We manually compute the regression equation:\n",
    "\n",
    "`prediction = b_0 + b_1 * appraisal_vars[:,0] + b_2 * appraisal_vars[:,1] + b_3 * appraisal_vars[:,2]`\n",
    "\n",
    "Thus, `prediction` is the mean of the Normal distribution that the linear regression model predicts.\n",
    "Finally, we condition on the observed data:\n",
    "\n",
    "`pyro.sample(\"obs\", Normal(prediction, 1), obs = emotion_data)`\n",
    "\n",
    "Notice we use `pyro.sample()` again. We draw a sample from a Normal with mean `prediction` and scale 1, but this time, we condition that this sample is equal to the observed `emotion_data`, using the argument `obs = ...`.\n",
    "\n",
    "\n",
    "And that's basically it for this function. Pyro's `irange()` and `iarange()` [functions](http://pyro.ai/examples/svi_part_ii.html#iarange) allow a flexible way to perform computations on individual datapoints while taking care of conditional independencies (the `i` in `irange()` and `iarange()`). One difference is that `iarange()` is vectorized, so we can perform the calculations on the entire data Tensor instead of individual observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression_model(data):\n",
    "    # define the parameters that control the gaussian prior over the regression coeffs.\n",
    "    # mean = 0, scale = 1\n",
    "    coeff_mean_prior = torch.tensor(0.0)\n",
    "    coeff_scale_prior = torch.tensor(1.0)\n",
    "    \n",
    "    # sample b_0 (intercept) and b_1 to b_3 (regression coeffs)\n",
    "    b_0 = pyro.sample(\"b_0\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
    "    b_1 = pyro.sample(\"b_1\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
    "    b_2 = pyro.sample(\"b_2\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
    "    b_3 = pyro.sample(\"b_3\", Normal(coeff_mean_prior, coeff_scale_prior))\n",
    "    \n",
    "    # loop over observed data\n",
    "    with pyro.iarange(\"map\", data.shape[0]):\n",
    "        outcome_data = data[:, :(OUTCOME_VAR_DIM)]\n",
    "        # Here, for simplification, we are only taking one emotion variable (happy)\n",
    "        # instead of all 8.\n",
    "        emotion_data = data[:, OUTCOME_VAR_DIM]  \n",
    "        appraisal_vars = compute_appraisal(outcome_data)\n",
    "        \n",
    "        # run the regression forward\n",
    "        prediction = b_0 + b_1 * appraisal_vars[:,0] + b_2 * appraisal_vars[:,1] + b_3 * appraisal_vars[:,2]\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\", Normal(prediction, 1), obs = emotion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: talk about guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression_guide(data):\n",
    "    coeff_mean_b0  = pyro.param(\"coeff_mean_b0\",  torch.tensor(0.0))\n",
    "    coeff_scale_b0 = pyro.param(\"coeff_scale_b0\", torch.tensor(1.0))\n",
    "    coeff_mean_b1  = pyro.param(\"coeff_mean_b1\",  torch.tensor(0.0))\n",
    "    coeff_scale_b1 = pyro.param(\"coeff_scale_b1\", torch.tensor(1.0))\n",
    "    coeff_mean_b2  = pyro.param(\"coeff_mean_b2\",  torch.tensor(0.0))\n",
    "    coeff_scale_b2 = pyro.param(\"coeff_scale_b2\", torch.tensor(1.0))\n",
    "    coeff_mean_b3  = pyro.param(\"coeff_mean_b3\",  torch.tensor(0.0))\n",
    "    coeff_scale_b3 = pyro.param(\"coeff_scale_b3\", torch.tensor(1.0))\n",
    "    # sample coefficients from Normal(mean, scale)\n",
    "    pyro.sample(\"b_0\", Normal(coeff_mean_b0, coeff_scale_b0))\n",
    "    pyro.sample(\"b_1\", Normal(coeff_mean_b1, coeff_scale_b1))\n",
    "    pyro.sample(\"b_2\", Normal(coeff_mean_b2, coeff_scale_b2))\n",
    "    pyro.sample(\"b_3\", Normal(coeff_mean_b3, coeff_scale_b3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can proceed to actually fit the model. The first step is to refresh the parameter store using `pyro.clear_param_store()`.\n",
    "\n",
    "We will use Stochastic Variational Inference `SVI()` which takes in the model and guide that we wrote above, as well as an optimization algorithm (here we use `torch.optim.Adam()`) and a loss function (here we use `Trace_ELBO()`). When `svi.step(data)` is called, it runs SVI over the `data`. Thus, here we simply define a loop that runs over the entire dataset `num_iterations` times. (We can easily modify this to do mini-batching, for example, for large datasets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 2.3637\n",
      "[iteration 0101] loss: 1.3586\n",
      "[iteration 0201] loss: 0.9622\n",
      "[iteration 0301] loss: 0.9521\n",
      "[iteration 0401] loss: 0.9502\n",
      "[iteration 0501] loss: 0.9407\n",
      "[iteration 0601] loss: 0.9445\n",
      "[iteration 0701] loss: 0.9491\n",
      "[iteration 0801] loss: 0.9429\n",
      "[iteration 0901] loss: 0.9464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcHFW99/HPb9bsewjZIAEiEIWwhBgQF7YQghe4KovXqwF5HvTKVbzqo+DGVVBBRZaXiER2RGQXZI8h7FlIIBCykUky2ZOZZJJZMmt3n+ePrp709PRS1dM9M5n5vl+veU3XqVNVp6eT+vVZy5xziIiI+FXQ1QUQEZEDiwKHiIgEosAhIiKBKHCIiEggChwiIhKIAoeIiASiwCEiIoEocIhkwczKzazBzOrifv5oZpea2ZspjnnVzBq9vNVm9rqZHZOQZ7KZPePtrzWz+WZ2Sue8KxF/FDhEsvdvzrkBcT//7eOY/3bODQCGAa8CD8Z2mNnhwFvAcmAiMAZ4CnjZzE7OeelFsqTAIdIFnHNh4O/A5Ljk/wUWOOd+4pyrcs7VOuduIxpcbuyCYookpcAh0gXMrAT4CrAwLvks4LEk2R8FPmVmfTujbCKZFHV1AUQOYP8ws1Dc9v8DWjIcc5uZ/R7oCzQCX4jbNwLYnuSY7US/5A0DtmZfXJHcUI1DJHsXOOeGxP38xccx33HODSEaOD4PPG5mx3r7dgGjkxwzGogAe3JSapEOUuAQ6QLOuYhz7g2gDJjhJf8LuDBJ9ouI9n3Ud1b5RNJRU5VI7pmZ9YlPcM41Jsl0MtHO8RVe0i+Ad8zsV8BNRJu9LgW+xv7gItLlVOMQyd4/E+ZxPOWlnwI0xP+YWexL2h9j+YmOlvqpc+4FAOfcWuBUYApQTrRv44vA2c65tzrtXYlkYHqQk4iIBKEah4iIBKLAISIigShwiIhIIAocIiISSI8cjjtixAg3YcKEri6GiMgBZenSpbuccyMz5euRgWPChAksWbKkq4shInJAMbONfvKpqUpERAJR4BARkUAUOEREJBAFDhERCUSBQ0REAlHgEBGRQBQ4REQkEAWODBpbwjy+dAtaRVhEJKpHTgDMpRteWM19b5czcmApn/1YxgmVIiI9nmocGVTURh/cVtcY6uKSiIh0DwocIiISiAKHiIgEosAhIiKBKHD49NCijTz3wfauLoaISJdT4MggNgr37XW7ufJv73ZtYUREugEFDhERCSSvgcPMhpjZ42a22sxWmdnJZjbMzOaa2Vrv91Avr5nZbWZWZmYfmNkJceeZ7eVfa2az81lmERFJL981jluBF51zRwFTgFXA1cA859wkYJ63DXAOMMn7uQK4A8DMhgHXAp8EpgHXxoKNiIh0vrwFDjMbDHwGuBvAOdfsnNsLnA/c72W7H7jAe30+8ICLWggMMbPRwNnAXOdclXNuDzAXmJmvcouISHr5rHFMBCqBe83sPTO7y8z6A6Occ7HhSTuAUd7rscDmuOO3eGmp0tswsyvMbImZLamsrMzxWxERkZh8Bo4i4ATgDufc8cA+9jdLAeCiKwfmZPVA59wc59xU59zUkSO1ppSISL7kM3BsAbY45xZ5248TDSQ7vSYovN8V3v6twPi448d5aanSRUSkC+QtcDjndgCbzexIL+kMYCXwDBAbGTUbeNp7/QzwNW901XSg2mvSegmYYWZDvU7xGV6aiIh0gXwvq/5t4CEzKwHWA5cRDVaPmtnlwEbgIi/v88AsoAyo9/LinKsys+uAd7x8v3TOVeW53CIikkJeA4dzbhkwNcmuM5LkdcCVKc5zD3BPbksnIiLZ0MxxEREJRIFDREQCUeAQEZFAFDiyVFHTiHM5mYIiInJAUeDIwtqdtUz79Tzue7u8q4siItLpFDiScM5x44ur2bh7X9L9G3ZF098q292ZxRIR6RbyPY/jgLRxdz13vLqOuSt3MumgAV1dHBGRbkU1jiQKzABobAkn3a+eDRHpzRQ4kigsjAaOcMSh/m8RkbYUOJIotP2BQ0RE2lLgSKLA+6tEMlQ3vPgiItKrKHAkYUQjQkg1DhGRdhQ40giHkwcO9XuISG+mwJGE88ZNqcYhItKeAkcaYVUtRETaUeBIxosXGlUlItKeAkcaChwiIu0pcCThN1xoNK6I9EYKHCIiEogCRxKZ+8TVhCUivZcCh4iIBKLAkYRTjUJEJCUFjg7QWlUi0hspcCSheX8iIqkpcIiISCAKHEmowiEikpoCh4iIBKLAkYTL0MmhPhAR6c0UOEREJBAFjiTiaxSa0yEi0pYCRweYljkUkV5IgUNERALJa+Aws3IzW25my8xsiZc2zMzmmtla7/dQL93M7DYzKzOzD8zshLjzzPbyrzWz2fkssx9qvBKR3qwzahynOeeOc85N9bavBuY55yYB87xtgHOASd7PFcAdEA00wLXAJ4FpwLWxYJMvGjUlIpJaVzRVnQ/c772+H7ggLv0BF7UQGGJmo4GzgbnOuSrn3B5gLjCzswstIiJR+Q4cDnjZzJaa2RVe2ijn3Hbv9Q5glPd6LLA57tgtXlqq9DbM7AozW2JmSyorKztYaFU5RERSKcrz+U91zm01s4OAuWa2On6nc86ZWU7u0s65OcAcgKlTp+rOLyKSJ3mtcTjntnq/K4CniPZR7PSaoPB+V3jZtwLj4w4f56WlSs9juf3l07LqItIb5S1wmFl/MxsYew3MAD4EngFiI6NmA097r58BvuaNrpoOVHtNWi8BM8xsqNcpPsNLExGRLpDPpqpRwFMW/VpeBPzNOfeimb0DPGpmlwMbgYu8/M8Ds4AyoB64DMA5V2Vm1wHvePl+6ZyrymO5M/ZwaNSViPRmeQsczrn1wJQk6buBM5KkO+DKFOe6B7gn12UUEZHgNHM8iUyr44qI9GYKHB2gznER6Y0UOJJQfUNEJDUFDhERCUSBIwl1cYiIpKbAISIigShwJJXhmePqBRGRXkyBIwM1W4mItKXAkYSChYhIagocHaBnjotIb6TAkUR8hWNdZV2XlUNEpDtS4MhgXeW+dmlqyhKR3kyBIwkFBhGR1BQ4REQkEAWOJDRPQ0QkNQWOJNRUJSKSmgJHR2g0roj0QgocSajGISKSmgJHFhRXRKQ3U+BIQp3jIiKpKXCIiEggChxJ+O3jUN+4iPRGChwiIhKIAoeIiASiwCEiIoEocCSheRwiIqkpcGTBKbKISC+mwJFEb5nHUb5rHxOufo431lZ2dVFE5ACiwNGLLd5QBcDTy7Z1cUlE5ECiwJGE73kcppkcItL7KHD0Zop7IpIFBY4kekcPh4hIdvIeOMys0MzeM7Nnve2JZrbIzMrM7BEzK/HSS73tMm//hLhzXOOlrzGzs/Nd5l5DEVJEstAZNY6rgFVx2zcCNzvnjgD2AJd76ZcDe7z0m718mNlk4BLg48BM4E9mVpjPAve24bZqsRKRIPIaOMxsHHAucJe3bcDpwONelvuBC7zX53vbePvP8PKfD/zdOdfknNsAlAHT8lnu3qZ3hUkR6ShfgcPMrjKzQRZ1t5m9a2YzfBx6C/BDIOJtDwf2OudC3vYWYKz3eiywGcDbX+3lb01Pckx8Ga8wsyVmtqSysmPzEnQjFRFJzW+N4+vOuRpgBjAU+CpwQ7oDzOzzQIVzbmnHiuiPc26Oc26qc27qyJEjO+OSvpp4tu5t4Kn3tuS9LB2hpioRCaLIZ77YvWUW8KBzboVlnsTwKeA8M5sF9AEGAbcCQ8ysyKtVjAO2evm3AuOBLWZWBAwGdselx8Qfkxe57OK46M8L2Lq3gc8fO4biQg1iE5EDn9872VIze5lo4HjJzAayv/kpKefcNc65cc65CUQ7t19xzn0FmA98ycs2G3jae/2Mt423/xUX7aV+BrjEG3U1EZgELPZZ7rwIElh21DTmryAd1FuWVhGR3PIbOC4HrgZOcs7VA8XAZVle80fA98ysjGgfxt1e+t3AcC/9e971cM6tAB4FVgIvAlc658JZXtunnnVDDYUj/OO9rb1utJiI5IffpqqTgWXOuX1m9p/ACUSbnXxxzr0KvOq9Xk+SUVHOuUbgwhTH/wr4ld/rdaX1lXWYGRNH9G+T3pX37DlvrOe3L67B4fj348e1ppt6N0QkC35rHHcA9WY2Bfg+sA54IG+l6mL+16pqn3b6Ta9x2u9fbX/OLqzFVNQ0AbBnX0uXlUFEeg6/gSPk9TecD/zROXc7MDB/xep5umMrkfo4RCQbfpuqas3sGqLDcD9tZgVE+zl6pFzeTg+EfgUt8isiQfitcVwMNBGdz7GD6JDY3+WtVD1Qd4gfqYrQHcomIgcOX4HDCxYPAYO9iX2Nzrle38cR6Jxd2CykGoWI5JLfJUcuIjp34kLgImCRmX0p/VE9k3MuqyAQNBit3VnLhl37fOdfUl7FhKufY11lXcCSKbCISDB++zh+QnQORwWAmY0E/sX+xQp7lHT9EvG7gtxvg4aas25+HYDyG871lT/2+Ne3ynZx+MgBAa8mIuKf3z6OgljQ8OwOcGyPEjQAxPLnu5O8I01h6uMQkSD81jheNLOXgIe97YuB5/NTpK7z0c5a/ueRZZzziYNT5sk2AHTWvVmtTiKSb74Ch3Pu/5nZF4kuXAgwxzn3VP6K1TUaW8Ks2FbDKYcPT5kn2wDQnb/Vq49DRILwW+PAOfcE8EQey9LlCrw7aDjt8o1ZBoFuHDhERIJIGzjMrJbktzwDnHNuUF5K1UVigSPis3M8iO44S7s714JEpPtKGzicc71qWZHCgliNI03gwAW64cby6iYtIj1FrxwZlUrsOUuhdIEj6xpH96O+DRHJhgJHnNamqjSBA7ILAt1xzapuWCQROQAocMSJNVWlq3HA/iCQ+em5ccdkX6ycSRW89FwOEQlCgSNOXjvH8xw50p1fgUFEckmBI06B387xLM7daaOqsui46I4jvkSk+1LgiFMYm8eRhxqH7s0i0lMocMQp8P4a4XDqu/ypN76SNAiUVdTy0oodKY8LEjc6uyNdTVkiEoTvmeO9gZ8ax576ltamnfjb7Zl/eD3tuYPEggx98yIiXUo1jjh+JgBmK0g/QiiSYc0TYEd1IwvW7Y47f2qpuj0Un0QkGwocccz8BY5sWpKCHOMncJ19y+t8+S8L26Wr0UlE8k2BI06sxpFuOG62gpyxJU0fS0x1Q0v2hfEoyIhINhQ44sT6OEIZbtx+gkBiB3eQDu9smso0C1xEOosCR5zWUVUZ7sJ+btKJ9/5cN1WlEmQah2KNiGRDo6riFPrs42iV5iYdjrjWpq+g0nWkT7j6Oa46Y5Kv85z/xzepqm9mxuTUTzQELXYoIsEocMTxO6rKzwipxH6SdDWOsopa9tS3cNKEYbELJBUr163z1ma8PsD7W6p95VMzl4gEocARx3ysVQV+m6oSAkeaYBObA1J+w7le3uRiw3QLTHM9RKTrqI8jQWGBZaxx+Bl11ZE+jlTnj3XaFxXk9mNTU5WIBKHAkaDQMgeO2A18d10z6yvrkuZpN6rKx7XDEceDCzfSHEo+ATB23fi+kyff3eLjzCIiuaPAkaCgIHMfR6xG8NpHlZx+02sp8rTd9jMc9+llW/nZPz7kj6+UJd3f4jVVxQeO7z36fsbzpqK+DRHJRt4Ch5n1MbPFZva+ma0ws1946RPNbJGZlZnZI2ZW4qWXettl3v4Jcee6xktfY2Zn56vM4K/G4WeCXmIVw889uqElDMDO2qak+2PlShysNeHq56hp7PiEQBERP/JZ42gCTnfOTQGOA2aa2XTgRuBm59wRwB7gci//5cAeL/1mLx9mNhm4BPg4MBP4k5kV5qvQBWYZ53Hc+OLqjOdJ7Az38+2+xHvoeZMXQBK1hKM1jqLC9h9bZU002ARZ6VZ9GyKSjbwFDhcV6wAo9n4ccDrwuJd+P3CB9/p8bxtv/xkWHeZ0PvB351yTc24DUAZMy1e5C3x0jvvRPlBkPmdJUfTjWLShKun+ZH0cMflYJkVEJJm89nGYWaGZLQMqgLnAOmCvcy7kZdkCjPVejwU2A3j7q4Hh8elJjom/1hVmtsTMllRWVmZd5sICI5KDwBFkHkdMSZKaBEBFbSMTrn6OJ7yO8MoUTVlBKdaISDbyGjicc2Hn3HHAOKK1hKPyeK05zrmpzrmpI0eOzPo8BWaEclHjyLCdTHGKwFFWEa24Pbhwo+/rJc2TIpOarEQkiE4ZVeWc2wvMB04GhphZbOLhOGCr93orMB7A2z8Y2B2fnuSYnCsptNa+hI5IvEn7+XZfXJT+40j3ZEI/TVWpJiGq5iEiQeRzVNVIMxvive4LnAWsIhpAvuRlmw087b1+xtvG2/+Ki45hfQa4xBt1NRGYBCzOV7mLiwr8jZrKoP08jsznLM6wtlVLmgc8pbv5q0IhIrmUzyVHRgP3eyOgCoBHnXPPmtlK4O9mdj3wHnC3l/9u4EEzKwOqiI6kwjm3wsweBVYCIeBK51zyYUc5UFxYkHICXhDtmqqCj+AFIBJxfOfh94D0w4DTzRPJ1BSlpioRCSJvgcM59wFwfJL09SQZFeWcawQuTHGuXwG/ynUZkykuLKC5i5qqkjU3VdU3s6uuGUg/MVGtTSLSWTRzPEFJYW6+frebx+Hj1p4suPjtf4jlU+1BRPJNgSNBqpFNQWWzyGGyLH4CTvR6qnOISOdQ4EiQq8AR5FGxMUlv/j5PEwtUqnCISL4pcCTINCTWr6wqANnHjawClYhINhQ4EuSqjyNRtp3j+WyC8tsMJiIST4EjQe76OHLTOe533ayOxRc1cImIfwocCXLXx5F+O+kxSdJCPicjdqxmopqHiPinwJEgZ4Ejw3YyyW7+oTSzxYOeX0QkFxQ4EpQU5abZ5sYXVvPqmorWbT+d18my+F1wMbaib3bzOHLfVLW7ronrnl1JKAeTKUWke1HgSFCQoxl0L67YwaX3vtO67W/12iQ1jk5pqsq9nz+zgrvf3MC81RVp8zWFwtz71oacPANFRDpHPteqOiAle0hSLvi5ryd78uD8DDfedMd2paYWfzWNP81fx63z1tK/pIiLThqf+QAR6XKqcSTIJnB888GlPnJlvrEn+9Z909yPfJXBZ1dIp4nVngoz1OCqG6LPSq9rCqXNJyLdhwJHgkw3umReXLEjYx5fNY4ONNdk24eSL7EaUIHPf2Hdq74kIukocCTIW1NVqvS4u3lHAkd3a6qKvZdMfUZalFHkwKPAkaCz+zjiY0VHOriziTm5ijU7qhup2tec9Ny5GmwgIt2HOscT5C9wJL9Lxz+mtiMjVyNpIoeluHm71v3ZXxdg+m/mAVB+w7mtabEah9+/p9baEjlwqMaRIF/fkJPdFssq6jjqZy+2bnekucnPsamby7K+bEqx2lPGpiotdyJywFHgSNCZTVUfbNnbZjvcgSpHrMaRLgi025fHb/n7A0feLiEiXUSBI0H+Osfb36QT79s+5/olFWupSneKNTtq+OU/V7Y2C8XyPrx4U/YXzlCeAkUOkR5HgSNBvgJH4h29oqax3bPN0/VTZBL7hp+sEhF7R/9Yto173trAbq8jO5/dCpoJLtJzqXM8QTbzOPyIv41GIo5pv57XLk9H+jhaA0eSOsfLK3e22Y69x/gO6VdW7+TXz6/mhas+nZOFHl2aQBZPg65EDjyqcSTIV9NK/A001cKFHfmWHps5HrtOfFDYsGtfxuOveXI5ZRV17K5rzpjXj1gQzHaIcWNLmE2763NSFhHJLQWOBEWd0MeRKkDkYgJg7Azp7teJefMh1grnN3AkZvvWQ+/ymd/N1zBdkW5IgSNBZ9Q4YuszJepQ4PCOXbhuN5D+hp2uPyRXWm/4mZqqUqS/4i3uqK4Ske5HfRwJOqOP4+xbXk+aJxdLoz+3fDu3k/6GGwo7jrn2JcYM6dtuX66eQx4LZB298YcjLn8DFkQkK6pxJMhbU1VcUMhHjSPIuRpawtQ2hVizs7bdvuufXQXAo0s289wH27O+fiRgH0eqgNXdnjMiIgoc7SQ2VU0ePSgn5/Vz+8vlQoXpHjmb7uFQzy2PBosfPv4BV/7t3ayvH4tbmW78mSp4Chwi3Y8CR4LEkahFhTmqgfi4/63cVpOTS11272KaQ6kDR0snPM41kqMOePVxiHQ/ChwJEm+4uWq68tN38MbaXTm51vw1le1Wq43XGYEj3LoESsfu/JpIKNL9KHAkqG1s+yS6Ir9PIsqgs1tcUs0VAWjJsLZJqpv9rromGprDvq4fmwWf6cmE1joZMVhZRKTrKHAk2NfU9saYqxE9nR440gSHZM1Y8ZWQVN/yp17/Ly66c4Gv6/tZOwtSD8dNPI+IdB8KHAnqmtqOeMpVH0dn3/8S18GKl6ypKv6b/fsJq/bGW7612tf1g46qSkVNVSLdT94Ch5mNN7P5ZrbSzFaY2VVe+jAzm2tma73fQ710M7PbzKzMzD4wsxPizjXby7/WzGbnq8wApxwxos12rvodOrvJJV3neLKgEj+i64t37K9VpDtPOrGA8e6mPb7OkfjXiY22UlOVSPeTzxpHCPi+c24yMB240swmA1cD85xzk4B53jbAOcAk7+cK4A6IBhrgWuCTwDTg2liwyYfTjjyIow4emPPzdvcaR6qVef+2aGPa62yvbmh9XVZR1/o6VlO487X1/OaFValPkKFC192epS4ieQwczrntzrl3vde1wCpgLHA+cL+X7X7gAu/1+cADLmohMMTMRgNnA3Odc1XOuT3AXGBmvsoN0Ke4sPX1V6cfmpNzZvrm3K+kMO3+oIIOx01Vuv/950r++f62lOe64oGlra/P/MNrra/j49Cq7dkPM1ZLlUj30yl9HGY2ATgeWASMcs7FpiTvAEZ5r8cCm+MO2+KlpUpPvMYVZrbEzJZUVlZ2qLwHD+rT+nr6YcM7dK6YdKOcAPoW5zZwvFWWuomtJZT5oVLxvv3weyn37W1IPuw3vm/DzzLtqa7fkWeUiEh+5D1wmNkA4Angu865Nl89XfRreE7uDM65Oc65qc65qSNHjuzQuW780rGtr3PVOZ5ulBNASVFuP4r73i5PuS9ZM1amTuwzbno10PXjb/gdGZmmmeMi3U9eA4eZFRMNGg855570knd6TVB4vyu89K3A+LjDx3lpqdLzZnDfYqYfNgzI3QTAdH0O4O9bea4ka8bKdINeV5n5mR7x4vsm0v0NLaGTY+3OWvbW76/FaFSVSPeTz1FVBtwNrHLO/SFu1zNAbGTUbODpuPSveaOrpgPVXpPWS8AMMxvqdYrP8NLyKnbDytU8jkw1js5cADZp53iO78/x5wsyifKsm1/ngtvfSnoeEeke8rms+qeArwLLzWyZl/Zj4AbgUTO7HNgIXOTtex6YBZQB9cBlAM65KjO7DnjHy/dL51xVHssN7O+TyFVNIH7RwYkj+vt6Kl++ZJrHkQvx5yv00dwXvyRL+e56DccV6cbyFjicc2+SerDlGUnyO+DKFOe6B7gnd6XLLFZDyFlTVVzz0LD+JWzd09Cm+aozb4/NSWo/2X6zT7WkSHwTU3G6pioNxxU54GjmeAqxGkdRjmoc1z+3fy5DOOJyt+puFpLVOIL0Jby8Ykfr68QaQesaVXHJhT6bqkJJ55f4LpaIdBIFjhTC3h0rHw92cs61O29nfrHOdjZ4zBUPLmVzVT3QvqaSbNjxE+9u4YM0y5hA9P1nM9pLRDqfAkcKoRx3jscLO9epo6gS5WJZ9f2Phm17Y39v056k+R95Z3PS9HjxAS32V4+d/2+LNjHr1jeyKKmI5JoCRwqxPo4BpUX84aIp3HrJcR0+Z6xZJxJpH5By9axvP3IROGK1g8RSXzxnYdJH46Z6d7G/Qn1zKOkCirEA9eOnlrMywwz0d8qrmL+mIm0eEek4BY4U4ofjfuGEcYwe3LfD52wJO/bsa2bl9pp2NY58tMgUp+hHaU4yczyo5lCEhuYw1fXtg8TFPpdeX7mtprVmd/v8dXz17sWt+/Y/erbtMfFzPOL9bdEmLvzzAi67952k+/NtT5oHZ4n0NAocKcSGz+ayE3tHdSMXz1ng67yHDOvX4euVpGgOy0WNY+Puembe+nrSfonVO2rbpa3cVsNFdy6gsSX6vJMNu/Yx67Y3mPP6+rTXSRy2fNwv5ybN9+Onlvstes4tWLeb46+by7xVO7usDCKdSYEjhViNIzZ5LdOwUT/Ou/1NPtoZXUE2VQ3jY6MGADByYGmHr9eSYqRUQ4u/p/ilc+Xf3mXj7nrf+Zdt3sviDVUs2xztJN9Z0+jruB889n5W5etM722O9ussLs/79CKRbkGBI4XYjT3WF5GLesfeuGadxJFN113wCQ4b0Z8TDx2Ws+ulGj21ZU9D0vTOlGkm/YEk9m8lcfkUkZ5KgSOFh/7vJ/nGZw5jaL9iIDc1jnhNobbf+k878iBe+cHnWofpnjghb48c6dAy5x0V+zOGAkzQeHtdbh6mlW+5/jci0l0pcKRw1MGDuGbW0Vjr3SD7u0KyZqdUtYHYTOlxQ/tRfsO5WV+zuwsyl+T9zW1HW2VahqSzlynRsijS2yhwdIL/mHZIu7SmuBvnf33u8NbXsZtQvhc9nHTQgPxeIIV/rdrJtU9/GKifJbEzvzkc4YEF5VwyJ/noraZQJOPNfNnmvexrCvkuQzKbvD6e/U1VIr1DPhc57FE60gyRbBRTbBhqv5JCfjTzqNb0H8w4kpaw4wvHj8t43pKigqxngc/93meZcPVzWR3bEX95YwMARx48yPcxiX+/2+ev47Z5a4HoEid/erWszf6jfvZi6+ulPz2T4QPa1vjqm0NccPtbfHrSCPoWF3LqpBF87eQJQd4GTy/bylV/X8ZvvnAMNY3RvqvYv5G1O2tZW1HHrGNGpz2Hc45XP6rks5NGUtCZyyOLdJBqHD7F/7e+59KpbfaNHRKd4zHv+59td9zIgaUcmeYZ5n0Snvw3fEApv79wCn3TPEr2f878GAAj+pe02ze4b3Hr64kj+qc8R76dN2VM2v0/f/pD3+fakzB3IxY0AN4s28XvX/4o5bHPJHnsbWyQwhtrd/Hyyp38/OkVaa//6+dX8fuX1rRJW7BuNwDXPLm8NRjGOsfPuvl1vvXQu2nFFIdXAAAPS0lEQVTPCfDChzu47N53uH9Beca8neFn//iQhxdv6upiyAFAgcOnWF/HyIGlnH7UqDb7vnvmJMpvOJfDRw5g9XUz+ZbX9DRmcB+e+OYpnDdlDHd+9cSk583mkbEneR3nIxL6Tp7/zqd57Jsnt27/27GjefQb+7djAa4zzPzEwWn3J65p9aevnJAy718Xpr6Zvf5R+scE3/Kvtfzo8Q9Yu7OWO19bx4MLyltrCPEa45rOqutbOOfWN1i0Phoc5ry+nj/Ob1ur2Z1kwt++5hAPLihvc853N+3h2w+/x47q6PDjm+d+xNTro3NRXvgwulhksmHN26sbmL+mgvWVdWnfXy49uHAj1zyZfj5MKBxh696uH5UnXUtNVT4lNiTcdOEUvu/NMYifzNenuLB1Rd0Lp47nkOHRiXyfmZT8cbalxf5i9+rrZrY2wQzoU9R6zuZQpHXC3cdGDWiztIcDJo8ZxJlHH8RPzp3MxBH9WVJexZB+0ZrKtInDWLwhP3MPJo7ozxs/PI1P/3a+r/yzjhnNiYcOZenG5GtdpXLXmxvS7q9uaOGRJZt5ZMn+tbK+dGL7ZsApv3iZN350Gne+tp4HFpTTEnZcPGchP/v85Db5ahpbOPZ/X056rXvfKm+zvae+mXvfKuef729j7sod3HPpSdzq1ZZWbKvmn15t6L63y9le3cCMyQfzwZa9rK2o422vRgPRzx6iEzrPuvk1xg7txwNfnwZE5xvVNYXa1DQTvVNexZ/ml3HR1PHsrGnk0k9NbJfH76TQG15YzV1vbuDNH53GuKEdn6QqByYFDp9i/7H6eDf6L544rjVwnHbkQW3yxobUxi9V3rekkD//54l8869LAfjO6Udw2ytlfPv0I3xdP9akNW3CMI4dN4Qnv3UKU8YN4QdnH9naV1FYYHGjwKIGlBZx1+yTWrenThjW+vrRb5wcqJ/j+2d9jJvmpm4Wijd6cB+G9CvhsW+ezIV/9rcEyQNfn8bZt7yedJ5JYYHl7DGyjy/d0i6tKRRh2q/mtUu/7tmVra+D9gn9+dV1rcGhsSXCf/xlUeu+c297s03el1bs5KUVyWeex/fZQPQxvje8sJo/v7auTfp5U8ZQUdvIwvVVFBUYoYhjxIBSdtU1ATB/TbR2tmZnLZW1zUydMJRh/UuIRBxvrN0/5PnO19axansNx44bQlMowtvrdjGgtIiqfc0s8r5onHrjfB775smEwo499c1s3F3Pw4s3cfpRB7FlTz1D+5WwakcNBw3sw9ghfWkJR2gORzjnE6NbV0petnkv4YjjqjMmEYo4GlvC1DWFqKxtalOe1z6qZObHD2ZnbSNfOH4sfYoLWb9rH8P6lXDI8H60hCNU7Wtm7JC+XP3kco4ZO5hzjxnNjppGJo7oz5PvbuGIgwZy0oShLNpQxcmHDeed8ir21Lewcls13/zs4fQrLWJvfTNjhvSlwIyahhZ21TUxalAfNlbVM7x/CbvqmjjioAHsrGnkkGH92VvfTE1jC32LCzl85ABWbKvhu48s46QJQ7lw6niq61tYv2sfL3y4nV+c93HMoo2ZdU0h6pvDHD6yP0P6lbC3vhkHjBncl/c27WHs0L4M6VtCfXOI6oYWnl++nSH9Sjj32NE8+/42PnnYcDZX1fNOeRVnTR5FcyjC4SMHUFZZx/ih/Thm3GBGDOj4BOJ0rCcOJZw6dapbsmRJTs9Zta+Zi+9cwA1fPKZ1kl4qDy/exDVPLuen5x7N//n0Ya3pi9bv5uI5C/nytEP4zReO8XXduSt3ctTBAxk/rB81jS2UFhVQWtS2eSt2Q4sN373rjfVc/9wqnv32qXxi7OCM1wiFI1wyZyGFBcZZk0exaEMVP551NIP6FPH1+95hfeU+aptC3P/1acy+ZzFTxg1mUN9i3li7iz995QRuenkN6yr3cd6UMa19CvFDiZ1z/HXRJn72jw8ZPbgP26vbzhr/3JEjue+y6DfoHz7+Po8u2cItFx/Hm2W7Wm/yt15yHFf9fRmprPv1LLZXN3DqjdEazkfXn8MpN8xjV10z9156Epfdt38NqyH9ijloYCkjB5byVtnupOf74cwj+e2La5Lui/n1vx9DYQEM7VfCFQ8uTZnv55+fzHXPraS4MPVghjGD+7DN+7sUFRhTxg8JXPsSAZj58YP5c4qm8UzMbKlzbmrGfAocuReJOJ54dwv/fvzYNg+Ccs7x+NItzDpmNP1Lc1fZq6xtYsW2aj6XUPPJlUjE0RgK06+kiKZQuDVwVdQ2ctDAPrSEI9z1xgYuPWUCL6/cwWcmjWRoko77jbv3MXZIXzZW1dO3uJDNVfXsqGnk344d0zqqqK4pxIMLNvKNzxzWZqRRKBzhqfe2ctTBg6htbOGEQ4dSWGDtFoucv7oCh+P0o0bR0BzG4ehXUsT9b5fzibGDaA45Tj58OBDtg6isbaKo0KioaaK4sICjRw9srbU9v3w7E0f05+jRg1qbhBZvqGJtRS0Xnji+zfycSMRRVlnHwD5F1DWGCDvH22W72VnbyI/OPqr1vSxcv5vK2iZKigoYNagPYwb3YenGPZxx9CgeW7qZo0cP4tixgwlFHDtrGtm6t4Ex3gKb72/Zy8fHDKK+OczQfiX0KymkuqGFxpYIjaEwG3fvY19TmIqaRsLOcfjIAUw/bDgvr9hB+e56/nP6IWzcXU9dU4iPjxnEh1tr2Lq3gSLv7zh+WD+KC40texqYftgwlm2upiUcoajAqG5o4ZBh/WgKRRg/rB8bdtVR0xBiYJ8iCsw4evQg9tY38+G2Go4cNZCWSIQhfYtpCTtOPHQor6yuoHzXPkYMLGHqocMoLDA2V9XTHI6wq66JfiVFDCgtwogulROORCgw46OdtQzsU8yx4wZT1xiif2kRu+qaCEccA/sUU1JUwKaqenZWNzJmSF+q6ptbvxTUN4XZXt3A4L7FFBYYNY0t1DaGOGhgH/Y1hRg/rB8fbNnLhOH9qWsKEXGOof1L2LKngQGlhdQ0hBjUt4jSokL6FheydW8DJUUFjB/aj8q6JiIRx/ABJRQWGNv2NtLQEiYcjnDI8H70KS4kHHGUFBZQ3xJmZ3UjNY0tOAcHD+5D3+JCzIyGljAjB5RSVGhsqNxH/9IiIs5RWlRAcWEBb5btYtSgUvqXFlFcUEBxkTGoTzHDB5RG/54DSok4Fy1bYQGD+hYzrH8JJx6a3QRiBY4uDBwiIgciv4FDo6pERCQQBQ4REQlEgUNERAJR4BARkUAUOEREJBAFDhERCUSBQ0REAlHgEBGRQHrkBEAzqwQ2duAUI4AD43mludHb3i/oPfcWes/BHOqcS74ia5weGTg6ysyW+Jk92VP0tvcLes+9hd5zfqipSkREAlHgEBGRQBQ4kpvT1QXoZL3t/YLec2+h95wH6uMQEZFAVOMQEZFAFDhERCQQBY44ZjbTzNaYWZmZXd3V5ckVMxtvZvPNbKWZrTCzq7z0YWY218zWer+HeulmZrd5f4cPzOyErn0H2TGzQjN7z8ye9bYnmtki7309YmYlXnqpt13m7Z/QleXuCDMbYmaPm9lqM1tlZif3gs/5f7x/1x+a2cNm1qenfdZmdo+ZVZjZh3FpgT9XM5vt5V9rZrOzLY8Ch8fMCoHbgXOAycCXzWxy15YqZ0LA951zk4HpwJXee7samOecmwTM87Yh+jeY5P1cAdzR+UXOiauAVXHbNwI3O+eOAPYAl3vplwN7vPSbvXwHqluBF51zRwFTiL7/Hvs5m9lY4DvAVOfcJ4BC4BJ63md9HzAzIS3Q52pmw4BrgU8C04BrY8EmMOecfqIDBE4GXorbvga4pqvLlaf3+jRwFrAGGO2ljQbWeK/vBL4cl78134HyA4zz/jOdDjwLGNHZtEWJnzfwEnCy97rIy2dd/R6yeM+DgQ2JZe/hn/NYYDMwzPvsngXO7omfNTAB+DDbzxX4MnBnXHqbfEF+VOPYL/YPMGaLl9ajeFXz44FFwCjn3HZv1w5glPe6J/wtbgF+CES87eHAXudcyNuOf0+t79fbX+3lP9BMBCqBe70murvMrD89+HN2zm0Ffg9sArYT/eyW0vM/awj+uebs81bg6EXMbADwBPBd51xN/D4X/QrSI8Zmm9nngQrn3NKuLksnKwJOAO5wzh0P7GN/8wXQsz5nAK+p5XyiQXMM0J/2TTo9Xmd/rgoc+20Fxsdtj/PSegQzKyYaNB5yzj3pJe80s9He/tFAhZd+oP8tPgWcZ2blwN+JNlfdCgwxsyIvT/x7an2/3v7BwO7OLHCObAG2OOcWeduPEw0kPfVzBjgT2OCcq3TOtQBPEv38e/pnDcE/15x93goc+70DTPJGY5QQ7WB7povLlBNmZsDdwCrn3B/idj0DxEZWzCba9xFL/5o3OmM6UB1XJe72nHPXOOfGOecmEP0cX3HOfQWYD3zJy5b4fmN/hy95+Q+4b+XOuR3AZjM70ks6A1hJD/2cPZuA6WbWz/t3HnvPPfqz9gT9XF8CZpjZUK+mNsNLC66rO3y60w8wC/gIWAf8pKvLk8P3dSrRauwHwDLvZxbRtt15wFrgX8AwL78RHWG2DlhOdMRKl7+PLN/754BnvdeHAYuBMuAxoNRL7+Ntl3n7D+vqcnfg/R4HLPE+638AQ3v65wz8AlgNfAg8CJT2tM8aeJhoH04L0Zrl5dl8rsDXvfdeBlyWbXm05IiIiASipioREQlEgUNERAJR4BARkUAUOEREJBAFDhERCUSBQySPzOy7Ztavq8shkksajiuSR97s9anOuV1dXRaRXFGNQyRHzKy/mT1nZu97z4a4luj6SfPNbL6XZ4aZLTCzd83sMW/9MMys3Mx+a2bLzWyxmR3Rle9FJB0FDpHcmQlsc85NcdFnQ9wCbANOc86dZmYjgJ8CZzrnTiA6w/t7ccdXO+eOAf7oHSvSLSlwiOTOcuAsM7vRzD7tnKtO2D+d6EPC3jKzZUTXFzo0bv/Dcb9PzntpRbJUlDmLiPjhnPvIe0znLOB6M5uXkMWAuc65L6c6RYrXIt2KahwiOWJmY4B659xfgd8RXdK8FhjoZVkIfCrWf+H1iXws7hQXx/1e0DmlFglONQ6R3DkG+J2ZRYiuYvpfRJucXjSzbV4/x6XAw2ZW6h3zU6IrMgMMNbMPgCaij/kU6ZY0HFekG9CwXTmQqKlKREQCUY1DREQCUY1DREQCUeAQEZFAFDhERCQQBQ4REQlEgUNERAL5/w2d8KsyKnK6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "# setup the optimizer with some learning rate\n",
    "optimizer = Adam({\"lr\": 0.005})\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(fit_regression_model, fit_regression_guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# do gradient steps\n",
    "losses = []\n",
    "for thisIteration in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    thisLoss = svi.step(outcome_emotion_dataset)\n",
    "    losses.append(thisLoss)\n",
    "    if thisIteration % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (thisIteration + 1, thisLoss / float(N_samples)))\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"ELBO\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3255805969238281, 0.02385237067937851, 0.48056650161743164, 0.041164662688970566, 0.651533305644989, 0.11297078430652618, 0.08928068727254868, 0.19496673345565796]\n"
     ]
    }
   ],
   "source": [
    "# output the learned variational parameters\n",
    "learnt_params = [pyro.param(\"coeff_mean_b0\").item(), pyro.param(\"coeff_scale_b0\").item(),\n",
    "                 pyro.param(\"coeff_mean_b1\").item(), pyro.param(\"coeff_scale_b1\").item(),\n",
    "                 pyro.param(\"coeff_mean_b2\").item(), pyro.param(\"coeff_scale_b2\").item(),\n",
    "                 pyro.param(\"coeff_mean_b3\").item(), pyro.param(\"coeff_scale_b3\").item()]\n",
    "print(learnt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
